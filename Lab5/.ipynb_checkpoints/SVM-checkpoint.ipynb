{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy.cluster.vq import *\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/hank/libsvm-3.24/python\")\n",
    "from svmutil import *\n",
    "\n",
    "from utilities import get_data, plot_heatmap, plot_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect train data feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.40946102142334\n",
      "(762332, 128)\n"
     ]
    }
   ],
   "source": [
    "des_list = []\n",
    "path = \"hw5_data/train/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    im = cv2.imread(File)\n",
    "    #im = cv2.resize(im, (200,200), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    des_list.append((File, des1))\n",
    "    #print(len(des1))\n",
    "\n",
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[1:]:\n",
    "    if descriptor is None:\n",
    "        print(0)\n",
    "        continue\n",
    "    #print(descriptor.shape)\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "    #print(descriptor.shape)\n",
    "#print(descriptors)\n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)\n",
    "\n",
    "print(descriptors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect test data feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.4496216773986816\n"
     ]
    }
   ],
   "source": [
    "test_list = []\n",
    "path = \"hw5_data/test/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    im = cv2.imread(File)\n",
    "    #im = cv2.resize(im, (200,200), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    test_list.append((File, des1))\n",
    "    #print(des1)\n",
    "    \n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enlarge feature number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 333.06759428977966\n"
     ]
    }
   ],
   "source": [
    "des_list = []\n",
    "path = \"hw5_data/train/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    im = cv2.imread(File)\n",
    "    im = cv2.resize(im, (600,600), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    des_list.append((File, des1))\n",
    "    #print(len(des1))\n",
    "\n",
    "descriptors = des_list[0][1]\n",
    "for image_path, descriptor in des_list[1:]:\n",
    "    if descriptor is None:\n",
    "        print(0)\n",
    "        continue\n",
    "    #print(descriptor.shape)\n",
    "    descriptors = np.vstack((descriptors, descriptor))\n",
    "    #print(descriptor.shape)\n",
    "#print(descriptors)\n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.012665033340454\n"
     ]
    }
   ],
   "source": [
    "test_list = []\n",
    "path = \"hw5_data/test/**/*\"\n",
    "\n",
    "t1 = time.time()\n",
    "files = glob.glob(path)\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for File in files:\n",
    "    im = cv2.imread(File)\n",
    "    im = cv2.resize(im, (1000,1000), interpolation = cv2.INTER_CUBIC)\n",
    "    kp1, des1 = sift.detectAndCompute(im,None)\n",
    "    test_list.append((File, des1))\n",
    "    #print(des1)\n",
    "    \n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K means for all feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1140.9546167850494\n"
     ]
    }
   ],
   "source": [
    "# Perform k-means clustering\n",
    "t1 = time.time()\n",
    "k = 300\n",
    "voc, variance = kmeans(descriptors, k, 1) \n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.283516 , 24.980072 , 26.57922  , ..., 47.75518  , 53.509296 ,\n",
       "        22.055067 ],\n",
       "       [98.815475 , 23.157852 ,  5.405956 , ...,  6.8360395,  5.0561466,\n",
       "        10.218122 ],\n",
       "       [18.010374 , 55.612926 , 82.49174  , ...,  5.682703 ,  9.713827 ,\n",
       "        39.472733 ],\n",
       "       ...,\n",
       "       [50.21564  , 85.94494  , 39.843777 , ..., 14.389107 , 17.855045 ,\n",
       "        21.147003 ],\n",
       "       [13.7968645, 10.390819 , 12.190155 , ..., 10.519499 ,  7.637784 ,\n",
       "         9.218813 ],\n",
       "       [18.49173  , 16.745148 , 16.463459 , ..., 13.846076 , 13.017975 ,\n",
       "        18.43502  ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of features based on K means center for each training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16075125  0.35780126 -0.42002752 ... -0.67930377  0.6170775\n",
      "   0.35780126]\n",
      " [-0.47099116 -0.92826414  0.44355482 ...  0.44355482  1.3581008\n",
      "  -0.01371818]\n",
      " [-0.6330898   0.35508364 -1.0283592  ... -0.2378204   4.703047\n",
      "   0.15744895]\n",
      " ...\n",
      " [-0.02461809 -1.1107069  -0.45905364 ...  0.19259968  1.0614707\n",
      "  -0.45905364]\n",
      " [-0.38540205  1.6160198   0.38437563 ... -1.0012242   0.07646455\n",
      "   0.38437563]\n",
      " [-0.36858153  1.5415338   0.48035866 ... -0.36858153  0.05588856\n",
      "  -0.36858153]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the histogram of features\n",
    "im_features = np.zeros((1500, k), \"float32\")\n",
    "for i in range(1500):\n",
    "    if des_list[i][1] is None:\n",
    "        continue\n",
    "    words, distance = vq(des_list[i][1],voc)\n",
    "\n",
    "    for w in words:\n",
    "        im_features[i][w] += 1\n",
    "        \n",
    "    im_features[i] = (im_features[i] - np.mean(im_features[i])) / np.std(im_features[i])\n",
    "    \n",
    "print(im_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram of features based on K means center for each testing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9034093  -1.0657126  -0.26016268 ... -0.70769036  1.7089591\n",
      "  -0.08115161]\n",
      " [-0.9183615  -1.2459577  -0.263169   ...  1.047216   -0.263169\n",
      "   0.06442728]\n",
      " [-0.6311171  -0.6311171   0.9401289  ... -0.10736844  0.41638023\n",
      "   1.4638776 ]\n",
      " ...\n",
      " [-0.05533787  0.4145118   0.25789526 ...  0.10127869  1.3542112\n",
      "  -0.52518755]\n",
      " [ 0.5408422  -1.0656196  -0.26238868 ... -0.4631964  -0.86481184\n",
      "   0.5408422 ]\n",
      " [-0.04705126 -0.04705126 -0.44466752 ... -0.44466752 -0.24585938\n",
      "  -0.64347565]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the histogram of features\n",
    "test_features = np.zeros((150, k), \"float32\")\n",
    "for i in range(150):\n",
    "    if test_list[i][1] is None:\n",
    "        continue\n",
    "    words, distance = vq(test_list[i][1],voc)\n",
    "    \n",
    "    for w in words:\n",
    "        test_features[i][w] += 1\n",
    "    test_features[i] = (test_features[i] - np.mean(test_features[i])) / np.std(test_features[i])\n",
    "\n",
    "print(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vocab.pkl', 'wb') as handle:\n",
    "    pickle.dump(voc, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('train_image_feats_1.pkl', 'wb') as handle:\n",
    "    pickle.dump(im_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('tEST_image_feats_1.pkl', 'wb') as handle:\n",
    "    pickle.dump(test_features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = get_data(gray=False)\n",
    "\n",
    "train_y = np.array([np.argmax(x) for x in train_y]).reshape(-1)\n",
    "test_y = np.array([np.argmax(x) for x in test_y]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_features = []\n",
    "for im in train_x:\n",
    "    kp, des = sift.detectAndCompute(im,None)\n",
    "    bag_of_features.append(des)\n",
    "bag_of_features = np.concatenate(bag_of_features, axis=0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "voc,_ = kmeans2(bag_of_features, 300, iter=1,minit='++')\n",
    "t2 = time.time()\n",
    "print(\"time:\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features = []\n",
    "\n",
    "for im in train_x:\n",
    "    kp, des = sift.detectAndCompute(im,None)\n",
    "    dist = distance.cdist(voc, des, metric='euclidean')\n",
    "    idx = np.argmin(dist, axis=0)\n",
    "    hist, bin_edges = np.histogram(idx, bins=len(voc))\n",
    "    hist_norm = [float(i)/sum(hist) for i in hist]\n",
    "    im_features.append(hist_norm)\n",
    "    \n",
    "im_features = np.asarray(im_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "\n",
    "for im in test_x:\n",
    "    kp, des = sift.detectAndCompute(im,None)\n",
    "    dist = distance.cdist(voc, des, metric='euclidean')\n",
    "    idx = np.argmin(dist, axis=0)\n",
    "    hist, bin_edges = np.histogram(idx, bins=len(voc))\n",
    "    hist_norm = [float(i)/sum(hist) for i in hist]\n",
    "    test_features.append(hist_norm)\n",
    "    \n",
    "test_features = np.asarray(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('vocab2.pkl', 'wb') as handle:\n",
    "    pickle.dump(voc, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('train_image_feats_2.pkl', 'wb') as handle:\n",
    "    pickle.dump(im_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('tEST_image_feats_2.pkl', 'wb') as handle:\n",
    "    pickle.dump(test_features, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kernel: linear')\n",
    "params = '-q -t 0 -s 0 -c 32'\n",
    "model = svm_train(train_y,im_features,params)\n",
    "pred, acc, _ = svm_predict(test_y,test_features, model)\n",
    "print(acc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Accuracy = 57.1333%\n",
      "[Linear] -5 57.13333333333333 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 54.8%\n",
      "[Linear] -4 54.800000000000004 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 55.4%\n",
      "[Linear] -3 55.400000000000006 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 57.0667%\n",
      "[Linear] -2 57.06666666666666 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 56.2667%\n",
      "[Linear] -1 56.266666666666666 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 56.8667%\n",
      "[Linear] 0 56.86666666666667 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 55.9333%\n",
      "[Linear] 1 55.93333333333334 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 54.2%\n",
      "[Linear] 2 54.2 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 56.2667%\n",
      "[Linear] 3 56.266666666666666 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 56.4667%\n",
      "[Linear] 4 56.46666666666667 (best: c=0.03125 acc=57.13333333333333)\n",
      "Cross Validation Accuracy = 57.2%\n",
      "[Linear] 5 57.199999999999996 (best: c=32 acc=57.199999999999996)\n"
     ]
    }
   ],
   "source": [
    "c_begin,c_end,c_step = (-5,5,1) # Cost\n",
    "best_acc = 0\n",
    "best_params = 0\n",
    "for c in range(c_begin,c_end+c_step,c_step):\n",
    "    \n",
    "    # Linear kernel\n",
    "    params = '-q -v 5 -s 0 -t 0 -c {}'.format(2**c)\n",
    "    acc = svm_train(train_y,im_features,params)\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_params = 2**c\n",
    "    print('[Linear] {} {} (best: c={} acc={})'.format(c,acc,best_params,best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kernel: linear')\n",
    "params = '-q -t 0 -s 0 -c 700'\n",
    "model = svm_train(train_y,im_features,params)\n",
    "pred2, acc2, _ = svm_predict(test_y,test_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
